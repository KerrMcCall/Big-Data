{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf642bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the MNIST Dataset\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(X_train.shape, X_test.shape)  # Loads the dataset and splits it into training (60,000 images) and testing (10,000 images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baadcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0a4272",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Displays the Shapes of the Dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(f\"Training set shape: {X_train.shape}, Test set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ede311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Preporocessing\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0 # Converts the Integers to Floats\n",
    "\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1) # Reshapes the Input data for CNN\n",
    "\n",
    "y_train_cat = to_categorical(y_train, 10)\n",
    "y_test_cat = to_categorical(y_test, 10) #Â One-hot Encodes the Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebe5ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the data into training (54,000 images) and validation (6,000 images)\n",
    "X_train, X_val, y_train_cat, y_val_cat = train_test_split(X_train, y_train_cat, test_size=0.1, random_state=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a612eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EDA\n",
    "#Display the first ten images from dataset in greyscale 28x28\n",
    "plt.figure(figsize=(10,5))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(X_train[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"Label: {np.argmax(y_train_cat[i])}\")\n",
    "    plt.axis('off')\n",
    "plt.suptitle(\"Sample MNIST Digits\")\n",
    "plt.show()\n",
    "\n",
    "# Plot bar chart displaying dataset balance\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "plt.bar(unique, counts)\n",
    "plt.title(\"Distribution of Digits in Training Set\")\n",
    "plt.xlabel(\"Digit\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b57c2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building the first model\n",
    "model_1 = Sequential([\n",
    "    Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_1 = model_1.fit(X_train, y_train_cat, epochs=5, batch_size=128, validation_data=(X_val, y_val_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b689dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting the training curve of the first model\n",
    "plt.plot(history_1.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history_1.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(\"Accuracy over Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b31e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building the second model\n",
    "model_2 = Sequential([\n",
    "    Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_2 = model_2.fit(X_train, y_train_cat, epochs=10, batch_size=128, validation_data=(X_val, y_val_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec29558",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting the training curve of the second model\n",
    "plt.plot(history_2.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history_2.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(\"Accuracy over Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b228a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building the third model\n",
    "model_3 = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model_3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_3 = model_3.fit(X_train, y_train_cat, epochs=12, batch_size=128, validation_data=(X_val, y_val_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b823cd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting the training curve of the third model\n",
    "plt.plot(history_3.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history_3.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(\"Accuracy over Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52698a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predictions for unseen data\n",
    "# Generate predictions for the test set\n",
    "y_pred = model_3.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Visualise predictions\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(10):\n",
    "    idx = np.random.randint(0, X_test.shape[0])\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_test[idx].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"Pred: {y_pred_classes[idx]} | True: {y_test[idx]}\")\n",
    "    plt.axis('off')\n",
    "plt.suptitle(\"Sample Predictions from Test Set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f077094",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Performance evaluation using classification metrics\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_classes))\n",
    "\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_classes), annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix on Test Set')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
